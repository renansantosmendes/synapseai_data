{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "827c0e44",
   "metadata": {
    "id": "827c0e44"
   },
   "source": [
    "## **Instalação dos Pacotes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3f010e",
   "metadata": {
    "id": "fe3f010e"
   },
   "outputs": [],
   "source": [
    "# !pip install -U -q langchain langchain-core langchain-openai langchain-community pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config_section",
   "metadata": {
    "id": "config_section"
   },
   "source": [
    "## **Configuração das Variáveis de Ambiente**\n",
    "\n",
    "Configuração da chave de API da OpenAI para autenticação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "env_config",
   "metadata": {
    "id": "env_config"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def load_env() -> None:\n",
    "    \"\"\"Load environment variables from the appropriate source.\n",
    "    \n",
    "    If running in Google Colab, loads secrets from Colab's userdata.\n",
    "    Otherwise, loads variables from a local .env file using python-dotenv.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import google.colab\n",
    "        from google.colab import userdata\n",
    "\n",
    "        os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_KEY\")\n",
    "\n",
    "    except ImportError:\n",
    "        from dotenv import load_dotenv\n",
    "        load_dotenv()\n",
    "\n",
    "\n",
    "load_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "import_section",
   "metadata": {
    "id": "import_section"
   },
   "source": [
    "## **Imports dos Pacotes Usados no Notebook**\n",
    "\n",
    "Importação dos componentes principais do LangChain para construção de aplicações com LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "65901d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2b1bfbf",
   "metadata": {
    "id": "a2b1bfbf"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88228d7",
   "metadata": {
    "id": "b88228d7"
   },
   "source": [
    "## **Inicialização do Modelo LLM**\n",
    "\n",
    "Criação da instância do modelo ChatGPT que será utilizado em todos os exemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0611fa0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0611fa0",
    "outputId": "ae56277c-c900-4e4c-d609-bd4d9aaa37dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo LLM inicializado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"openai:gpt-4.1-nano\")\n",
    "\n",
    "print(\"Modelo LLM inicializado com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eac1927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Olá! Tudo ótimo, obrigado. Como posso ajudar você hoje?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 13, 'total_tokens': 26, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_336de151a4', 'id': 'chatcmpl-DDiMhPdHpHfFhhMZlUDI0Se9T1apL', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c9d09-85b1-7fe1-b486-8ec3427a79a9-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 13, 'output_tokens': 13, 'total_tokens': 26, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"olá, tudo bem?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "KZNd83DTtnpv",
   "metadata": {
    "id": "KZNd83DTtnpv"
   },
   "outputs": [],
   "source": [
    "file_url = \"https://raw.githubusercontent.com/renansantosmendes/synapseai_data/refs/heads/main/company_context.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "K6pk7GqFtqDu",
   "metadata": {
    "id": "K6pk7GqFtqDu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(file_url, encoding=\"utf-8\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9RCkAvH39qLm",
   "metadata": {
    "id": "9RCkAvH39qLm"
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, constr\n",
    "from typing import List, Dict\n",
    "\n",
    "class ProductAnalysis(BaseModel):\n",
    "    \"\"\"Associação de um produto aos seus problemas.\"\"\"\n",
    "    product_name: str = Field(description=\"Nome do produto\")\n",
    "    problems: List[str] = Field(description=\"Lista de problemas identificados para este produto\")\n",
    "\n",
    "class ProductsProblems(BaseModel):\n",
    "    \"\"\"Estrutura final para a extração de múltiplos produtos.\"\"\"\n",
    "    content: List[ProductAnalysis] = Field(description=\"Lista de produtos e seus problemas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "_nQpiBrmKWs5",
   "metadata": {
    "id": "_nQpiBrmKWs5"
   },
   "outputs": [],
   "source": [
    "llm_structured = llm.with_structured_output(ProductsProblems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4139df",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "<context>\n",
    "Com base na seguinte descrição e detalhes da empresa gere a descrição do\n",
    "produto e seu nome. O nome deve ser o mais curto possível, sem adicionar a descrição.\n",
    "O campo descrição deve ser feito de forma separada do nome do produto\n",
    "</context>\n",
    "\n",
    "<company_description>\n",
    "{company_description}\n",
    "</company_description>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "zIOAJMk5R8Ai",
   "metadata": {
    "id": "zIOAJMk5R8Ai"
   },
   "outputs": [],
   "source": [
    "products_improvement_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "<context>\n",
    "Com base na seguinte descrição e detalhes da empresa gere a descrição do\n",
    "produto e seu nome. O nome deve ser o mais curto possível, sem adicionar a descrição.\n",
    "O campo descrição deve ser feito de forma separada do nome do produto\n",
    "\n",
    "Siga os passos para criar toda parte detalhada:\n",
    "- Crie os requisitos funcionais e não funcionais que o produto deve apresentar\n",
    "- Use o contexto do produto para criar ainda mais detalhes sobre os seguintes pontos: ferramentas usadas, \n",
    "modelos usados, abordagem, integrações com outros sistemas, integrações e ferramentas de observabilidade, \n",
    "detalhes do deploy, fonte de dados, privacidade, detalhes da escalabilidade (volume, cargas, uso de memória), \n",
    "versionamento de prompts e modelos\n",
    "\n",
    "Garanta que a linguagem é uma linguagem técnica, evite a todo custo uma linguagem de négocios.\n",
    "</context>\n",
    "\n",
    "<product_name>\n",
    "{product_name}\n",
    "</product_name>\n",
    "\n",
    "<product_description>\n",
    "{product_description}\n",
    "</product_description>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "iOWgGL5HSlJK",
   "metadata": {
    "id": "iOWgGL5HSlJK"
   },
   "outputs": [],
   "source": [
    "class ProductEntry(BaseModel):\n",
    "    \"\"\"Representa um produto individual da companhia e sua definição oficial.\"\"\"\n",
    "    name: str = Field(\n",
    "        description=\"O nome oficial do produto (ex: 'Cartão Platinum', 'App Invest', 'CDB Fácil')\"\n",
    "    )\n",
    "    description: str = Field(\n",
    "        description=\"A descrição detalhada e técnica de todas das funcionalidades e regras do produto encontrada no texto\"\n",
    "    )\n",
    "    \n",
    "class ProductSpecification(BaseModel):\n",
    "    product_name: str = Field(description=\"Nome do produto\")\n",
    "    detailed_description: str = Field(description=\"Descrição técnica detalhada nos mínimos detalhesdo produto\")\n",
    "\n",
    "class CompanyProductCatalog(BaseModel):\n",
    "    \"\"\"Catálogo completo de produtos extraído dos documentos da empresa.\"\"\"\n",
    "    products: List[ProductEntry] = Field(\n",
    "        description=\"Lista de todos os produtos identificados no texto contendo suas descrições detalhadas\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "EdmOjrD3SHYP",
   "metadata": {
    "id": "EdmOjrD3SHYP"
   },
   "outputs": [],
   "source": [
    "product_chain = (\n",
    "    products_prompt | \n",
    "    llm.with_structured_output(\n",
    "        schema=CompanyProductCatalog, \n",
    "        method=\"function_calling\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "product_improvement_chain = (\n",
    "    products_improvement_prompt | \n",
    "    init_chat_model(\n",
    "        model=\"openai:gpt-4.1-mini\"\n",
    "        ).with_structured_output(\n",
    "            schema=ProductSpecification, \n",
    "            method=\"function_calling\"\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kWlKB-2Rz2r6",
   "metadata": {
    "id": "kWlKB-2Rz2r6"
   },
   "source": [
    "## Criação da lista de produtos + descrições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "iV2xGlu6S0al",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iV2xGlu6S0al",
    "outputId": "1e4c7612-1457-4f64-a479-0a66ba9bb1d2"
   },
   "outputs": [],
   "source": [
    "catalog = product_chain.invoke(\n",
    "    {\n",
    "        \"company_description\": docs[0].page_content\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "DQHHa_r01KCf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DQHHa_r01KCf",
    "outputId": "9d5b5a07-4109-4f2f-f112-647a5d618d1d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ProductEntry(name='FinBrain', description='O FinBrain é um copiloto financeiro corporativo que transforma dados financeiros complexos em insights claros, explicáveis e acionáveis. Ele permite que executivos, controllers e analistas façam perguntas em linguagem natural sobre resultados financeiros, projeções e indicadores-chave, reduzindo drasticamente o tempo gasto em análises manuais e relatórios. Com o FinBrain, decisões financeiras tornam-se mais rápidas, fundamentadas e transparentes, melhorando a comunicação entre áreas técnicas e a alta liderança.'),\n",
       " ProductEntry(name='RiskGen', description='O RiskGen é uma plataforma de IA generativa que automatiza e padroniza análises de risco regulatório, compliance e auditoria, permitindo que organizações lidem com contratos e normas complexas com muito mais eficiência e segurança. Ele reduz riscos operacionais, aumenta a consistência das análises e fornece suporte técnico confiável para áreas jurídicas, de compliance e de auditoria interna.'),\n",
       " ProductEntry(name='EduMentor AI', description='O EduMentor AI é um tutor educacional inteligente que oferece aprendizado personalizado e adaptativo, ajustando explicações, exemplos e exercícios ao nível e ao ritmo de cada aluno. Ele amplia a escala do ensino, melhora o engajamento dos alunos e reduz a sobrecarga de professores e instrutores, sendo ideal tanto para educação formal quanto em ambientes corporativos.'),\n",
       " ProductEntry(name='CourseGen Studio', description='O CourseGen Studio é uma plataforma de criação de cursos baseada em IA generativa que acelera a produção de conteúdo educacional estruturado e pedagogicamente consistente. Ele permite que instituições e empresas criem cursos completos em minutos, mantendo controle total sobre qualidade, estilo e alinhamento institucional.'),\n",
       " ProductEntry(name='ClinicaGPT', description='O ClinicaGPT é um assistente clínico baseado em IA generativa que apoia profissionais de saúde na organização de informações, consulta a protocolos e elaboração de documentos clínicos. Ele melhora a eficiência do atendimento, reduz carga administrativa e aumenta a segurança clínica, sempre mantendo o profissional de saúde como responsável pela decisão final.')]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog.products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "DsQSYv8i1pLZ",
   "metadata": {
    "id": "DsQSYv8i1pLZ"
   },
   "outputs": [],
   "source": [
    "catalog_dict = {item['name']: item['description'] for item in catalog.model_dump()[\"products\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "x6mXZHzm1xbp",
   "metadata": {
    "id": "x6mXZHzm1xbp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O FinBrain é um copiloto financeiro corporativo que transforma dados financeiros complexos em insights claros, explicáveis e acionáveis. Ele permite que executivos, controllers e analistas façam perguntas em linguagem natural sobre resultados financeiros, projeções e indicadores-chave, reduzindo drasticamente o tempo gasto em análises manuais e relatórios. Com o FinBrain, decisões financeiras tornam-se mais rápidas, fundamentadas e transparentes, melhorando a comunicação entre áreas técnicas e a alta liderança.\n"
     ]
    }
   ],
   "source": [
    "current_product = \"FinBrain\"\n",
    "print(catalog_dict.get(current_product))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b51f02",
   "metadata": {},
   "source": [
    "## Adição de detalhes ao produto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "070e8c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_product = product_improvement_chain.invoke(\n",
    "    {\n",
    "        \"product_name\": current_product,\n",
    "        \"product_description\": catalog_dict.get(current_product, \"\")\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5bacf612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Requisitos Funcionais:\\n1. Interface de Pergunta em Linguagem Natural: Permite que usuários façam perguntas sobre dados financeiros e receban respostas precisas e explicáveis.\\n2. Análise de Dados Financeiros: Realiza processamento e análise de grandes volumes de dados financeiros corporativos, como balanços, demonstrativos de resultados, e indicadores-chave.\\n3. Geração de Insights e Projeções: Oferece projeções financeiras baseadas em dados históricos e modelos preditivos.\\n4. Explicabilidade dos Resultados: Fornece a fundamentação lógica e técnica para os insights gerados para suportar decisões.\\n5. Suporte a Múltiplos Usuários Corporativos: Permite o uso por executivos, controllers e analistas com diferentes níveis de permissão.\\n6. Dashboards Interativos: Visualização de dados e insights por meio de dashboards interativos e customizáveis.\\n\\nRequisitos Não Funcionais:\\n1. Segurança e Privacidade: Garantia de confidencialidade dos dados financeiros, com criptografia ponta a ponta e conformidade com GDPR.\\n2. Alto Desempenho: Processamento em tempo real ou quase real para respostas rápidas.\\n3. Escalabilidade: Capacidade de suportar milhões de registros financeiros e múltiplos acessos simultâneos sem perda de performance.\\n4. Alta Disponibilidade: Sistema com tolerância a falhas, replicação e failover para 99,9% de uptime.\\n5. Manutenibilidade: Arquitetura modular para fácil atualização de modelos e componentes.\\n\\nDetalhes Técnicos:\\n- Ferramentas usadas: Python para backend analítico, frameworks de NLP (como Hugging Face Transformers) para interpretação das perguntas em linguagem natural e geração de respostas.\\n- Modelos usados: Modelos de linguagem baseados em Transformers ajustados para terminologia financeira e interpretação de dados, modelos de machine learning para projeções financeiras.\\n- Abordagem: Pipeline de processamento que recebe dados financeiros tradicionais, transforma para formato compatível, aplica análise preditiva e gera insights explicáveis.\\n- Integrações: Integração com ERP corporativos e bancos de dados financeiros via APIs RESTful, suporte a bancos SQL e NoSQL.\\n- Observabilidade: Logs centralizados com ELK Stack (Elasticsearch, Logstash, Kibana), métricas de performance via Prometheus e alertas configuráveis via Grafana.\\n- Deploy: Utilização de contêineres Docker orquestrados por Kubernetes para escalabilidade e alta disponibilidade, deploy em nuvem privada ou pública.\\n- Fonte de Dados: Dados financeiros estruturados extraídos de sistemas ERP, data warehouses e fontes financeiras externas confiáveis.\\n- Privacidade: Implementação de criptografia AES para dados armazenados e TLS para comunicação, políticas rígidas de acesso baseadas em roles.\\n- Escalabilidade: Arquitetura escalável horizontalmente para suportar aumento de volume de dados e usuários simultâneos. Uso eficiente de memória com processamento em batch e streaming.\\n- Versionamento: Controle rigoroso de versões para prompts e modelos ML via sistemas como MLflow e Git, permitindo reprodutibilidade e auditoria.\\n\\nEssa descrição técnica detalha o FinBrain como uma solução robusta e escalável para a análise financeira corporativa avançada, integrando tecnologias modernas de NLP, ML e infraestrutura de nuvem para decisões financeiras otimizadas.'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detailed_product.detailed_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "40efb417",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: ClinicaGPT: 100%|██████████| 5/5 [00:43<00:00,  8.78s/it]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "products description improved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "detailed_catalog_dict = {}\n",
    "customer_dict = {}\n",
    "\n",
    "pbar = tqdm.tqdm(catalog_dict.keys())\n",
    "for product_key in pbar:\n",
    "    pbar.set_description(f\"Processing: {product_key}\")\n",
    "    \n",
    "    detailed_product = product_improvement_chain.invoke(\n",
    "        {\n",
    "            \"product_name\": product_key,\n",
    "            \"product_description\": catalog_dict.get(product_key, \"\")\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    detailed_catalog_dict[product_key] = detailed_product.detailed_description\n",
    "    \n",
    "    \n",
    "\n",
    "print(\"products description improved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "78754c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FinBrain'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "4f015ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FinBrain': 'O FinBrain é um copiloto financeiro corporativo avançado que utiliza processamento de linguagem natural (PLN) e aprendizado automático para transformar dados financeiros complexos em insights claros, explicáveis e acionáveis. Funcionalmente, o produto deve suportar consulta em linguagem natural sobre dados financeiros históricos, projeções e indicadores-chave de desempenho (KPIs), fornecendo respostas precisas e contextualizadas. Além disso, deve permitir integração com sistemas ERP, CRM e bancos de dados financeiros para extração automática e atualização em tempo real dos dados. Não funcionalmente, o produto deve garantir alta disponibilidade (>99,9%), baixa latência de respostas (<200ms), segurança robusta com criptografia ponta a ponta e conformidade com normas de privacidade de dados (ex: LGPD). A arquitetura do FinBrain utiliza modelos de linguagem grandes (LLMs), fine-tuned para domínio financeiro, associados a modelos estatísticos de séries temporais para previsão de indicadores. Ferramentas usadas incluem Python para backend, frameworks de deep learning PyTorch e TensorFlow, além de serviços de contêinerização Docker e orquestração Kubernetes para deploy escalável. Para observabilidade, o sistema incorpora Prometheus para métricas, Grafana para dashboards e Elastic Stack para logs, permitindo monitoramento efetivo de performance e detecção pró-ativa de falhas. A fonte dos dados abrange ERPs principais, bases de mercado financeiro e bases internas via APIs seguras. O sistema é projetado para suportar cargas elevadas de dados, processando milhões de registros financeiros em memória distribuída, com escalabilidade horizontal via clusters Kubernetes. O versionamento de prompts e modelos é gerenciado via sistema Git integrado com pipelines CI/CD, permitindo atualização contínua dos modelos e ajustes finos dos prompts para melhorar precisão e relevância das respostas. Privacidade é assegurada por anonimização de dados sensíveis e políticas de acesso baseadas em função (RBAC). O FinBrain é implantado em nuvem privada ou híbrida para atender requisitos corporativos rígidos de segurança e conformidade.',\n",
       " 'RiskGen': 'Requisitos Funcionais:\\n- Automatização da análise de risco regulatório, compliance e auditoria.\\n- Padronização dos relatórios e outputs gerados.\\n- Suporte técnico para interpretação de cláusulas contratuais e normas regulatórias.\\n- Integração com sistemas jurídicos, plataformas de gestão documental e bases regulatórias.\\n- Capacidade de geração de relatórios detalhados para diferentes níveis hierárquicos.\\n\\nRequisitos Não Funcionais:\\n- Alta disponibilidade e tolerância a falhas.\\n- Segurança robusta para manipulação de dados sensíveis.\\n- Baixa latência na geração dos resultados.\\n- Escalabilidade para volumes elevados de documentos e regras.\\n- Conformidade com normas de privacidade e proteção de dados (ex: LGPD, GDPR).\\n\\nFerramentas Usadas:\\n- Frameworks de IA generativa baseados em Transformers e Large Language Models.\\n- Infraestrutura em nuvem para deploy (AWS, Azure ou GCP).\\n- Ferramentas de orquestração de containers (Kubernetes).\\n- Sistemas de monitoramento (Prometheus, Grafana) para observabilidade.\\n\\nModelos Usados:\\n- Modelos de linguagem customizados para entendimento jurídico e regulatório.\\n- Modelos de NLP para extração de informações, classificação e análise contextual.\\n\\nAbordagem:\\n- Pipeline automatizado para ingestão, pré-processamento, análise e geração de outputs.\\n- Utilização de técnicas de fine-tuning para adaptação dos modelos às especificidades locais.\\n- Sistema de versionamento de prompts e modelos garantindo reprodutibilidade e auditoria.\\n\\nIntegrações:\\n- APIs para integração com ERPs, sistemas jurídicos, bancos de dados regulatórios.\\n- Webhooks para atualização em tempo real dos dados e análises.\\n\\nObservabilidade:\\n- Logs estruturados e métricas de performance acompanhadas via dashboards.\\n- Alertas automáticos para falhas, degradação de performance e eventos críticos.\\n\\nDeploy:\\n- Contêineres dockerizados para facilidade de deploy e rollback.\\n- Estratégias de deploy contínuo (CI/CD) com testes automatizados.\\n\\nFonte de Dados:\\n- Bases de normas regulatórias oficiais.\\n- Repositórios de contratos internos e externos.\\n- Dados de auditorias anteriores e casos de compliance.\\n\\nPrivacidade:\\n- Criptografia em trânsito e em repouso.\\n- Políticas de acesso restrito e autenticação multifatorial.\\n\\nEscalabilidade:\\n- Arquitetura distribuída para altas cargas de documentos simultâneos.\\n- Balanceamento de carga para uso eficiente de CPU e memória.\\n- Monitoramento proativo para alocação dinâmica de recursos.\\n\\nVersionamento:\\n- Controle de versão dos modelos e prompts via sistemas Git integrados.\\n- Histórico completo de alterações para fins de auditoria e controle de qualidade.',\n",
       " 'EduMentor AI': 'Requisitos Funcionais:\\n- Capacidade de avaliar o nível cognitivo e estilo de aprendizado do aluno.\\n- Geração dinâmica de conteúdo educacional adaptado (explicações, exemplos, exercícios).\\n- Sistema de feedback em tempo real para ajustes pedagógicos.\\n- Registro detalhado do progresso do aluno.\\n\\nRequisitos Não Funcionais:\\n- Alta disponibilidade e baixa latência no atendimento a múltiplas sessões simultâneas.\\n- Segurança robusta e conformidade com LGPD para proteção de dados dos usuários.\\n- Escalabilidade horizontal para suportar aumento de usuários.\\n- Interface programática para integração com sistemas educacionais existentes.\\n\\nDetalhes Técnicos:\\n- Ferramentas usadas incluem Python para o backend, TensorFlow para modelos de aprendizado adaptativo e React para frontend.\\n- Modelos de NLP baseados em transformers personalizados para geração e adaptação de conteúdo educacional.\\n- Abordagem baseada em aprendizado reforçado para melhorar recomendações pedagógicas com base no feedback do usuário.\\n- Integrações via APIs RESTful com LMS corporativos e plataformas educacionais.\\n- Ferramentas de observabilidade incluem Prometheus para métricas, Grafana para dashboards e Elastic Stack para logs centralizados.\\n- Deploy realizado em Kubernetes, com uso de containers Docker para portabilidade e escalabilidade.\\n- Fontes de dados derivadas de bases educacionais públicas e dados anonimizados dos usuários para treino contínuo.\\n- Privacidade garantida com criptografia de dados em trânsito e repouso, além de anonimização para análises.\\n- Escalabilidade projetada para suportar até milhões de usuários simultâneos, com balanceamento de carga e uso otimizado de cache.\\n- Versionamento rigoroso dos prompts e modelos por meio de ferramentas de controle de versão Git e DVC (Data Version Control).',\n",
       " 'CourseGen Studio': 'Requisitos Funcionais:\\n- Geração automatizada de conteúdo educacional baseado em IA generativa.\\n- Interface para personalização de estilos e alinhamento institucional dos cursos.\\n- Suporte à criação rápida de cursos completos com módulos, aulas e avaliações.\\n- Controle de qualidade do conteúdo gerado com validação pedagógica integrada.\\n- Exportação dos cursos em formatos padrão (SCORM, xAPI).\\n- Gestão de usuários e permissões para colaboradores e revisores.\\n\\nRequisitos Não Funcionais:\\n- Alta disponibilidade e desempenho para suportar múltiplos usuários simultâneos.\\n- Segurança robusta para proteção dos dados institucionais e dos usuários.\\n- Sistema escalável para suportar crescimento em volume de criação e acessos.\\n- Interface web responsiva e acessível.\\n- Logs detalhados e monitoramento para análises operacionais.\\n\\nDetalhes Técnicos:\\n- Ferramentas usadas: Python e frameworks web React para frontend, backend baseado em contêineres Docker.\\n- Modelos de IA: Utilização de modelos de linguagem GPT-4 customizados para geração de conteúdos educativos estruturados.\\n- Abordagem: Pipeline de criação que integra etapas de geração, validação automática de coerência pedagógica e edição colaborativa.\\n- Integrações com LMS (Learning Management Systems) populares via APIs REST para exportação e sincronização de cursos.\\n- Ferramentas de observabilidade: Prometheus para monitoramento de métricas, Grafana para dashboards, e ELK Stack para logging e análise de logs.\\n- Deploy: Orquestração em Kubernetes para escalabilidade e resiliência com CI/CD automatizado.\\n- Fonte de dados: Base de dados relacional para metadados dos cursos e repositórios de dados externos para conteúdos de referência.\\n- Privacidade: Criptografia de dados em repouso e em trânsito, conformidade com GDPR e LGPD.\\n- Escalabilidade: Armazenamento e memória otimizados para suportar geração simultânea de múltiplos cursos, escala horizontal com balanceamento de carga.\\n- Versionamento: Sistema de controle de versões para prompts e modelos de IA permitindo rollback e melhoria contínua.',\n",
       " 'ClinicaGPT': 'Requisitos Funcionais:\\n1. Organização e gerenciamento de informações clínicas para profissionais de saúde.\\n2. Consulta dinâmica a protocolos clínicos atualizados.\\n3. Elaboração automatizada de documentos clínicos, incluindo laudos e prontuários.\\n4. Interface intuitiva para interação do usuário com o assistente IA.\\n5. Registro e versionamento das interações e documentos gerados.\\n6. Controle de acesso baseado em perfis de usuário para garantir segurança.\\n7. Logs detalhados para auditoria e rastreabilidade.\\n\\nRequisitos Não Funcionais:\\n1. Alta disponibilidade e resiliência para uso contínuo em ambientes clínicos.\\n2. Baixa latência na geração de respostas para garantir fluidez no atendimento.\\n3. Escalabilidade horizontal para suportar aumento de usuários simultâneos.\\n4. Conformidade com normas de privacidade e segurança de dados de saúde (LGPD, HIPAA).\\n5. Implementação de criptografia para dados em trânsito e em repouso.\\n6. Monitoramento contínuo da performance e integridade do sistema.\\n\\nDetalhes Técnicos:\\n- Ferramentas Usadas: Plataforma de IA utilizando modelos de linguagem baseados em transformers, preferencialmente GPT-4 ou superior, com uso de Kubernetes para orquestração de containers.\\n- Modelos Usados: Modelos de linguagem treinados em corpora clínicos e científicos, com fine-tuning específico para linguagem médica e protocolos clínicos.\\n- Abordagem: Uso de modelos generativos para geração de texto assistida, combinado com sistemas de busca semântica para consulta a protocolos.\\n- Integrações: Integração via API RESTful com sistemas eletrônicos de prontuário eletrônico (EPD), sistemas hospitalares e bases de dados clínicas.\\n- Observabilidade: Implementação de ferramentas como Prometheus para métricas, Grafana para dashboards e ELK Stack para logs centralizados.\\n- Deploy: Deployment em ambiente cloud híbrido com uso de CI/CD para atualizações contínuas, com versionamento claro de modelos e prompts.\\n- Fonte de Dados: Bases de dados clínicas validadas, bibliotecas de protocolos oficiais e documentos médicos, com atualizações periódicas.\\n- Privacidade: Dados dos pacientes anonimizados antes do processamento, uso de tokens seguros e mecanismos de autenticação robustos.\\n- Escalabilidade: Suporte para atingir milhares de requisições simultâneas, uso otimizado de memória através de técnicas de caching e compressão de modelos.\\n- Versionamento: Controle rigoroso de versões de prompts e modelos com sistema de rollback rápido para garantir estabilidade em produção.'}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detailed_catalog_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WEGavdL-zLBN",
   "metadata": {
    "id": "WEGavdL-zLBN"
   },
   "source": [
    "## Criação do público de cada produto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "aa9e0f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomerAnalysis(BaseModel):\n",
    "    \"\"\"Análise detalhada de um cliente potencial para um produto.\"\"\"\n",
    "    customer_name: str = Field(description=\"Nome do cliente\")\n",
    "    customer_description: str = Field(description=\"Descrição detalhada do cliente\")\n",
    "\n",
    "class PublicTargetAnalysis(BaseModel):\n",
    "    \"\"\"Análise detalhada do público-alvo de um produto, incluindo jornada do cliente e exemplos reais.\"\"\"\n",
    "    target_audience_description: str = Field(description=\"Descrição detalhada do público-alvo para o produto\")\n",
    "    customer_journey: str = Field(description=\"Descrição da jornada de uso do produto, desde o primeiro contato até o uso recorrente\")\n",
    "    example_customers: List[CustomerAnalysis] = Field(\n",
    "        description=\"Lista de possíveis clientes reais que se encaixariam no público-alvo, com breve descrição de cada um\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cxkQOFdyzO6B",
   "metadata": {
    "id": "cxkQOFdyzO6B"
   },
   "outputs": [],
   "source": [
    "customer_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "<context>\n",
    "Com base na seguinte descrição e detalhes da empresa gere uma descrição\n",
    "de um público alvo para o produto, uma possivel jornada de uso do produto, \n",
    "desde o primeiro contato do cliente com o produto, até o uso recorrente do mesmo.\n",
    "Além disso, gere uma lista de possíveis clientes que sejam reais e que se encaixariam \n",
    "no público alvo do produto com uma breve descrição de cada um desses clientes.\n",
    "</context>\n",
    "\n",
    "<company_description>\n",
    "{company_description}\n",
    "</company_description>\n",
    "\n",
    "Considere o produto \"{product_name}\" e sua descrição \"{product_description}\" para conseguir gerar problemas mais\n",
    "contextualizados\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "85e3dbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_structured_llm = llm.with_structured_output(PublicTargetAnalysis, method=\"function_calling\")\n",
    "customer_chain = customer_prompt | customer_structured_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddc9d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_dict = {}\n",
    "for product_key in detailed_catalog_dict.keys():\n",
    "    customers = customer_chain.invoke(\n",
    "        {\n",
    "            \"company_description\": docs[0].page_content,\n",
    "            \"product_name\": product_key,\n",
    "            \"product_description\": catalog_dict.get(product_key)\n",
    "        }\n",
    "    )\n",
    "    customers_dict[product_key] = customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b12cd6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'customer_name': 'João Silva',\n",
       "  'customer_description': 'Controller de uma grande empresa do setor de energia, responsável por consolidar relatórios financeiros trimestrais e estratégicos, buscando agilidade para análises complexas e conformidade regulatória.'},\n",
       " {'customer_name': 'Maria Fernandes',\n",
       "  'customer_description': 'Diretora financeira de uma holding de investimentos, que necessita de insights rápidos sobre a saúde financeira de diferentes portfólios e de suporte na tomada de decisões de alocação de recursos.'},\n",
       " {'customer_name': 'Carlos Pereira',\n",
       "  'customer_description': 'Analista de finanças de uma fintech com alto volume de transações e necessidade de relatórios precisos para investidores e órgãos reguladores, buscando automação e confiabilidade nos dados.'},\n",
       " {'customer_name': 'Luana Costa',\n",
       "  'customer_description': 'Gerente de controladoria de um conglomerado industrial, interessada em reduzir o tempo de elaboração de relatórios financeiros e melhorar a comunicação com a diretoria por meio de insights mais claros e rastreáveis.'}]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers.model_dump().get(\"example_customers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1c5b9a",
   "metadata": {},
   "source": [
    "# usar esse for aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76846ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for current_product in catalog_dict.keys():\n",
    "    print(current_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ttzBCu630CyY",
   "metadata": {
    "id": "ttzBCu630CyY"
   },
   "source": [
    "## Criação dos problemas para cada produto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "80765254",
   "metadata": {},
   "outputs": [],
   "source": [
    "problems_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "<context>\n",
    "Com base na seguinte descrição e detalhes de uma empresa gere uma lista de\n",
    "possíveis problemas que cada produto da empresa pode apresentar do ponto de\n",
    "vista do usuário final, como por exemplo API instável, sistema demora muito\n",
    "para responder,\n",
    "</context>\n",
    "\n",
    "<company_description>\n",
    "{company_description}\n",
    "</company_description>\n",
    "\n",
    "Use o contexto do produto \"{product_name}\" e sua descrição \"{product_description}\" para conseguir criar cenários de problemas reais para \n",
    "a abertura de tickets de suporte contextualizados. Garanta que os problemas listados sejam realmente relacionados ao produto e não sejam \n",
    "problemas genéricos de mercado.\n",
    "\n",
    "Use as informações a seguir para conseguir gerar os problemas de cada produto:\n",
    "\n",
    "## Informações sobre o produto:\n",
    "- Descrição do público-alvo: {target_audience_description}\n",
    "- Jornada do cliente: {customer_journey}\n",
    "- Exemplos de clientes: {example_customers}\n",
    "\n",
    "Crie problemas especificos para o produto em questão. \n",
    "\n",
    "Gere dados que evidencie o problema para cada um dos problemas listados, como por exemplo: porcentagem de clientes afetados, \n",
    "impacto financeiro, quantidade de vezes que o problema aconteceu, horários nos quais os problemas ocorrem, etc. \n",
    "\n",
    "Use termos técnicos e específicos do domínio do produto para descrever os problemas, evitando generalizações e garantindo que cada problema seja claramente relacionado ao produto em questão.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "asr_EVZOLa9z",
   "metadata": {
    "id": "asr_EVZOLa9z"
   },
   "outputs": [],
   "source": [
    "problems_chain = (\n",
    "    problems_prompt | \n",
    "    llm.with_structured_output(\n",
    "        schema=ProductAnalysis, \n",
    "        method=\"function_calling\"\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "Xbz-w5spLJPk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xbz-w5spLJPk",
    "outputId": "6c01bf0f-7877-40d0-f75b-54b607509862"
   },
   "outputs": [],
   "source": [
    "problems_response = problems_chain.invoke({\n",
    "    \"product_name\" : current_product,\n",
    "    \"product_description\": detailed_catalog_dict.get(current_product),\n",
    "    \"company_description\": docs[0].page_content,\n",
    "    \"target_audience_description\": customers.model_dump().get(\"target_audience_description\"),\n",
    "    \"customer_journey\": customers.model_dump().get(\"customer_journey\"),\n",
    "    \"example_customers\": customers.model_dump().get(\"example_customers\"),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "Eq1LhjGgXMs7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eq1LhjGgXMs7",
    "outputId": "16b68ba1-0ee1-4001-b0db-8103a74c56bb"
   },
   "outputs": [],
   "source": [
    "product_dict = problems_response.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "NmiPAIGvY9ag",
   "metadata": {
    "id": "NmiPAIGvY9ag"
   },
   "outputs": [],
   "source": [
    "# product_problems_dict = {item['product_name']: item['problems'] for item in problems_response.model_dump().get(\"problems\")}\n",
    "product_problems_dict = {product_dict['product_name']: product_dict['problems']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "tiC79ITCa1Ij",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tiC79ITCa1Ij",
    "outputId": "88f5eefa-dd3c-440c-d171-86c69892eaea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FinBrain': ['Latência de respostas superior a 200ms durante consultas complexas de grandes volumes de dados financeiros, afetando aproximadamente 15% dos usuários em horários de pico, o que resulta em aumento de 30% no tempo de análise e dificuldades na tomada de decisões estratégicas.',\n",
       "  'Inconsistência nos dados retornados em consultas de projeções financeiras de múltiplos períodos, especialmente ao trabalhar com bases de dados específicas de clientes como ERP SAP e Oracle, gerando, em média, 5 ocorrências semanais por cliente, impactando a confiabilidade dos relatórios em 25%.',\n",
       "  'Falha na integração automática de dados em tempo real com sistemas ERP em 40% das tentativas de sincronização, principalmente em ambientes híbridos de nuvem privada e on-premise, levando à utilização de dados desatualizados em até 4 horas, afetando decisões de fluxo de caixa e alocação de orçamento.',\n",
       "  'Problemas de indisponibilidade do serviço de API, apresentando queda de aproximadamente 2 horas por semana em média, principalmente em horários de alta demanda, impactando cerca de 20% do volume de consultas que dependem de integrações com outros sistemas corporativos, resultando em atrasos na elaboração de relatórios financeiros.',\n",
       "  'Dificuldade na precisão das respostas ao fazer perguntas em linguagem natural sobre indicadores financeiros específicos, especialmente em cenários de análise de séries temporais com dados históricos confusos ou incompletos, levando a uma taxa de erro estimada de 12% nas respostas geradas, e impactando usuários em setores de controle e auditoria com maior criticidade.']}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_problems_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "p0gMmIO7xzVa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p0gMmIO7xzVa",
    "outputId": "3f3e607d-9bbd-42fb-d634-047a1528994e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Produto escolhido: Seguro Vida\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def get_random_element(input_list):\n",
    "    \"\"\"Selects random elements from a list\"\"\"\n",
    "    return random.choice(input_list) if input_list else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7556b6d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['FinBrain'])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_problems_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f9d91dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Falha na integração automática de dados em tempo real com sistemas ERP em 40% das tentativas de sincronização, principalmente em ambientes híbridos de nuvem privada e on-premise, levando à utilização de dados desatualizados em até 4 horas, afetando decisões de fluxo de caixa e alocação de orçamento.'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_random_element(product_problems_dict.get(current_product))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfe8e1f",
   "metadata": {},
   "source": [
    "## Execução do enriquecimento inicial, antes da criação do ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a8ec84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "ebe784f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: FinBrain:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product details improved!\n",
      "Customer details improved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: RiskGen:  20%|██        | 1/5 [00:18<01:13, 18.34s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product problems identified!\n",
      "Product details improved!\n",
      "Customer details improved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: EduMentor AI:  40%|████      | 2/5 [00:33<00:49, 16.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product problems identified!\n",
      "Product details improved!\n",
      "Customer details improved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: CourseGen Studio:  60%|██████    | 3/5 [00:49<00:32, 16.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product problems identified!\n",
      "Product details improved!\n",
      "Customer details improved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: ClinicaGPT:  80%|████████  | 4/5 [01:04<00:15, 15.64s/it]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product problems identified!\n",
      "Product details improved!\n",
      "Customer details improved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: ClinicaGPT: 100%|██████████| 5/5 [01:18<00:00, 15.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product problems identified!\n",
      "products description improved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "detailed_catalog_dict = {}\n",
    "customers_dict = {}\n",
    "product_problems_dict = {}\n",
    "\n",
    "pbar = tqdm.tqdm(catalog_dict.keys())\n",
    "for product_key in pbar:\n",
    "    pbar.set_description(f\"Processing: {product_key}\")\n",
    "    \n",
    "    detailed_product = product_improvement_chain.invoke(\n",
    "        {\n",
    "            \"product_name\": product_key,\n",
    "            \"product_description\": catalog_dict.get(product_key, \"\")\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    detailed_catalog_dict[product_key] = detailed_product.detailed_description\n",
    "    print(\"Product details improved!\")\n",
    "    \n",
    "    customers = customer_chain.invoke(\n",
    "        {\n",
    "            \"company_description\": docs[0].page_content,\n",
    "            \"product_name\": product_key,\n",
    "            \"product_description\": detailed_catalog_dict.get(product_key)\n",
    "        }\n",
    "    )\n",
    "    customers_dict[product_key] = customers\n",
    "    print(\"Customer details improved!\")\n",
    "    \n",
    "    problems_response = problems_chain.invoke({\n",
    "        \"product_name\" : product_key,\n",
    "        \"product_description\": detailed_catalog_dict.get(product_key),\n",
    "        \"company_description\": docs[0].page_content,\n",
    "        \"target_audience_description\": customers_dict[product_key].model_dump().get(\"target_audience_description\"),\n",
    "        \"customer_journey\": customers_dict[product_key].model_dump().get(\"customer_journey\"),\n",
    "        \"example_customers\": customers_dict[product_key].model_dump().get(\"example_customers\"),\n",
    "    })\n",
    "    \n",
    "    product_problems_dict[product_key] = problems_response.model_dump().get(\"problems\")\n",
    "    print(\"Product problems identified!\")\n",
    "\n",
    "print(\"products description improved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c439f9",
   "metadata": {},
   "source": [
    "## Criação dos Tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "9a7af2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from enum import Enum\n",
    "from typing import List\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "class CriticalityLevel(str, Enum):\n",
    "    LOW = \"Baixa\"\n",
    "    MEDIUM = \"Média\"\n",
    "    HIGH = \"Alta\"\n",
    "    CRITICAL = \"Crítica\"\n",
    "\n",
    "class SupportTicket(BaseModel):\n",
    "    \"\"\"Estrutura de um ticket de suporte com dados realistas.\"\"\"\n",
    "    customer_name: str = Field(description=\"Nome completo real (ex: João Carlos de Alencar, Maria Aparecida Souza)\")\n",
    "    customer_email: str = Field(description=\"E-mail variado (NÃO use @example.com. Use @gmail, @uol, @empresa.com.br, etc)\")\n",
    "    product_name: str = Field(description=\"Nome do produto do mercado financeiro ou tecnologia\")\n",
    "    issue_description: str = Field(description=\"Relato do problema em linguagem natural humana\")\n",
    "    opening_date: str = Field(description=\"Data de abertura (formato ISO YYYY-MM-DD)\")\n",
    "    criticality: CriticalityLevel = Field(description=\"Nível de urgência\")\n",
    "\n",
    "class TicketBatch(BaseModel):\n",
    "    \"\"\"Lote de tickets para exportação.\"\"\"\n",
    "    tickets: List[SupportTicket]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "yNikm4tJM5Aq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yNikm4tJM5Aq",
    "outputId": "13a54bdd-0a2e-4a34-b100-2b13f2389e9b"
   },
   "outputs": [],
   "source": [
    "\n",
    "ticket_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"Você é um gerador de dados sintéticos de alta fidelidade para o mercado brasileiro.\n",
    "\n",
    "    DIRETRIZES PARA REALISMO:\n",
    "    - NOMES: Use nomes brasileiros reais e diversos (sobrenomes como Silva, Oliveira, Cavalcanti, Schmidt, Nogueira).\n",
    "    - E-MAILS: Use domínios como @hotmail.com, @uol.com.br, @terra.com.br, @gmail.com ou domínios de empresas fictícias (@startup.io, @banco.com.br).\n",
    "    Se for criar um nome de empresa fictícia, garanta que o domínio do e-mail seja condizente com o nome da empresa (ex: nome da empresa: \"TechNova\", e-mail: \"funcionario@technova.io\").\n",
    "    - PROIBIÇÃO: Está proibido o uso do domínio '@example.com'.\n",
    "    - DATAS: Gere datas aleatórias no ano de 2025.\n",
    "    - PERSONAS: Varie entre clientes corporativos sérios e usuários comuns informais.\"\"\"),\n",
    "    (\"human\", \"Gere um ticket de suporte para o produto '{product_name}' com a seguinte descrição '{product_description}' sobre o problema: '{product_problem}'.\"),\n",
    "    (\"human\", \"Garanta que o problema seja único e especifico para aquele cliente em questão.\"),\n",
    "    (\"human\", \"Gere os detalhes e dados que evidencie o problema para cada um dos problemas listados, como por exemplo: porcentagem de clientes afetados, impacto financeiro, quantidade de vezes que o problema aconteceu, horários nos quais os problemas ocorrem, etc. Use termos técnicos e específicos do domínio do produto para descrever os problemas, evitando generalizações e garantindo que cada problema seja claramente relacionado ao produto em questão.\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "4ad48b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickets_chain = (\n",
    "    ticket_prompt | init_chat_model(\n",
    "    model=\"openai:gpt-4.1-mini\",\n",
    "    temperature=0.8\n",
    "    ).with_structured_output(\n",
    "        schema=SupportTicket,\n",
    "        method=\"function_calling\"\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ace573",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_tickets = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "5f686bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['FinBrain', 'RiskGen', 'EduMentor AI', 'CourseGen Studio', 'ClinicaGPT'])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_problems_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "16ae318a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RiskGen'"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_random_element(list(product_problems_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904777f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               customer_name                        customer_email  \\\n",
      "0  Bruno Henrique Cavalcanti  bruno.cavalcanti@financesmart.com.br   \n",
      "\n",
      "  product_name                                  issue_description  \\\n",
      "0     FinBrain  A API de consulta em linguagem natural do FinB...   \n",
      "\n",
      "  opening_date criticality  \n",
      "0   2025-04-15        Alta  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "input_data = {\n",
    "    \"product_name\": product_key,\n",
    "    \"product_description\": detailed_catalog_dict.get(product_key),\n",
    "    \"product_problem\": get_random_element(product_problems_dict.get(product_key))\n",
    "}\n",
    "\n",
    "ticket = tickets_chain.invoke(input_data)\n",
    "df = pd.DataFrame([ticket.model_dump(mode='json')])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e832e313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['API de consulta em linguagem natural apresenta alta latência, frequentemente excedendo o limite de 2 segundos, especialmente durante horários de pico (entre 9h e 12h), afetando aproximadamente 35% dos usuários simultâneos.',\n",
       " 'Sistema de geração de relatórios dinâmicos falha ao integrar dados de diversas fontes de ERP e BI, resultando em relatórios incompletos ou incorretos em 18% das tentativas de exportação, impactando especialmente os clientes do setor financeiro e de indústrias de manufatura.',\n",
       " 'Mecanismo de controle de acesso baseado em perfis apresenta falhas intermitentes na autenticação de usuários com privilégios sensíveis, levando a uma taxa de erro de autenticação de 7% durante auditorias internas realizadas após às 20h.',\n",
       " 'A camada de caching inteligente não está alinhada com a atualização em tempo real dos bancos de dados financeiros, causando divergências de até 3 dias entre os dados exibidos pelo FinBrain e os dados originais, o que compromete a confiabilidade das análises para clientes como o Banco ABC.',\n",
       " 'Monitoramento de métricas via Prometheus e Grafana não detecta quedas de performance durante aumentos de volume de consultas, levando a uma deterioração de SLA de 99,9% para cerca de 97% em períodos de alta demanda, como fechamento de ciclo financeiro mensal.']"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_problems_dict.get(\"FinBrain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "6qaFWKUaO6jT",
   "metadata": {
    "id": "6qaFWKUaO6jT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sistema de geração de relatórios dinâmicos falha ao integrar dados de diversas fontes de ERP e BI, resultando em relatórios incompletos ou incorretos em 18% das tentativas de exportação, impactando especialmente os clientes do setor financeiro e de indústrias de manufatura.'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_random_element(product_problems_dict.get(current_product))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "95a8d492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           customer_name              customer_email product_name  \\\n",
      "0  Renata Silva Oliveira  renata.oliveira@startup.io     FinBrain   \n",
      "\n",
      "                                   issue_description opening_date criticality  \n",
      "0  A API de consulta em linguagem natural do FinB...   2025-02-15        Alta  \n"
     ]
    }
   ],
   "source": [
    "input_data = {\n",
    "    \"product_name\": product_key,\n",
    "    \"product_description\": detailed_catalog_dict.get(product_key),\n",
    "    \"product_problem\": get_random_element(product_problems_dict.get(product_key))\n",
    "}\n",
    "\n",
    "ticket = tickets_chain.invoke(input_data)\n",
    "df = pd.DataFrame([ticket.model_dump(mode='json')])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56104169",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
